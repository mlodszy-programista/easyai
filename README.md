# easyai

**EasyAI** is a lightweight C# application that makes it easy to run local AI models through a simple web interface.

Designed with simplicity and flexibility in mind, EasyAI allows you to serve your own AI models locally and interact with them via a minimal HTML front-end â€” all without the need for complex setups or cloud dependencies.

## âœ¨ Features

- ğŸ§  **Run Local AI Models** â€” Easily host and interact with local `.gguf` models.
- ğŸŒ **Web Interface** â€” Includes a minimal HTML front-end for interacting with the model in your browser.
- âš™ï¸ **Configurable** â€” Define paths, default models, and other parameters in a simple `appsettings.json` file.
- ğŸ–¥ï¸ **Windows Service Support** â€” Optionally run EasyAI as a Windows service for always-on availability.

## ğŸ› ï¸ Getting Started

1. Clone the repository.
2. Configure the `appsettings.json` file:
   - Set the path to your model directory.
   - Choose a default `.gguf` model.
3. Run the application â€” either as a standalone app or install it as a Windows service.


## Acknowledgements

This project uses the following open-source components:

- [**LlamaSharp**](https://github.com/SciSharp/LLamaSharp) â€“ MIT License  
  A C# binding for llama.cpp, providing a managed interface for running LLaMA models.

- [**llama.cpp**](https://github.com/ggerganov/llama.cpp) â€“ MIT License  
  Backend engine used by LlamaSharp for model inference.

- [**Meta Llama 3**](https://ai.meta.com/llama) model weights â€“ Â© Meta Platforms, Inc.  
  Used under the Meta Llama 3 Community License.
